version: '3.8'

services:
  # Redis Cache
  redis:
    image: redis:alpine
    container_name: rag-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    networks:
      - rag-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # Backend API
  backend:
    build: .
    container_name: rag-backend
    ports:
      - "8001:8001"
    environment:
      - PHOENIX_ENDPOINT=http://phoenix:6006
      - DATABASE_URL=${DATABASE_URL:-sqlite:///./storage/database.db}
      - REDIS_URL=redis://redis:6379/0
      - CACHE_TTL=${CACHE_TTL:-3600}
      - DB_POOL_SIZE=${DB_POOL_SIZE:-20}
      - DB_MAX_OVERFLOW=${DB_MAX_OVERFLOW:-40}
      - OLLAMA_BASE_URL=http://ollama:11434
      - SECRET_KEY=${SECRET_KEY:-change-me-in-production}
      - FRONTEND_URL=${FRONTEND_URL:-http://localhost:3000}
    volumes:
      - ./data:/app/data
      - ./storage:/app/storage
      - ./.env:/app/.env:ro
    depends_on:
      - phoenix
      - redis
    networks:
      - rag-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Phoenix Monitoring
  phoenix:
    image: arizephoenix/phoenix:latest
    container_name: rag-phoenix
    ports:
      - "6006:6006"
    volumes:
      - ./phoenix_data:/data
    networks:
      - rag-network
    restart: unless-stopped

  # Ollama (LLM local) - Optionnel si tu utilises un service externe
  # DÃ©commente si tu veux utiliser Ollama dans Docker
  # ollama:
  #   image: ollama/ollama:latest
  #   container_name: rag-ollama
  #   ports:
  #     - "11434:11434"
  #   volumes:
  #     - ollama_data:/root/.ollama
  #   networks:
  #     - rag-network
  #   restart: unless-stopped
  #   deploy:
  #     resources:
  #       reservations:
  #         devices:
  #           - driver: nvidia
  #             count: 1
  #             capabilities: [gpu]

  # Nginx Load Balancer (optionnel)
  # nginx:
  #   image: nginx:alpine
  #   container_name: rag-nginx
  #   ports:
  #     - "80:80"
  #     - "443:443"
  #   volumes:
  #     - ./nginx-load-balancer.conf:/etc/nginx/conf.d/default.conf
  #   depends_on:
  #     - backend
  #   networks:
  #     - rag-network
  #   restart: unless-stopped

networks:
  rag-network:
    driver: bridge

volumes:
  redis_data:
  # ollama_data:

