# ðŸ¤– Support Multi-LLM

## ðŸ“‹ Vue d'ensemble

Le systÃ¨me supporte plusieurs fournisseurs de LLM.

## ðŸ”§ Fournisseurs SupportÃ©s

### 1. Ollama (par dÃ©faut)

Configuration dans `.env` :
```env
OLLAMA_BASE_URL=http://localhost:11434
LLM_MODEL_NAME=llama3
```

### 2. OpenAI

Configuration dans `.env` :
```env
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-3.5-turbo
```

### 3. HuggingFace

Configuration dans `.env` :
```env
HUGGINGFACE_API_KEY=hf_...
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.1
```

### 4. Anthropic (Claude)

Configuration dans `.env` :
```env
ANTHROPIC_API_KEY=sk-ant-...
ANTHROPIC_MODEL=claude-3-sonnet-20240229
```

## ðŸ”— Endpoints

### Lister les LLM disponibles

```bash
GET /llms
```

Retourne :
```json
{
  "llms": [
    {
      "name": "ollama_default",
      "provider": "ollama",
      "model_name": "llama3",
      "is_default": true
    },
    {
      "name": "openai_default",
      "provider": "openai",
      "model_name": "gpt-3.5-turbo",
      "is_default": false
    }
  ]
}
```

### Informations sur un LLM

```bash
GET /llms/{llm_name}
```

### Utiliser un LLM spÃ©cifique

```bash
POST /ask?llm_name=openai_default
```

## ðŸš€ Ajouter un LLM personnalisÃ©

En Python :
```python
from app.llm_manager import get_llm_manager, LLMProvider

manager = get_llm_manager()
manager.add_llm(
    name="my_custom_llm",
    provider=LLMProvider.OLLAMA,
    model_name="mistral",
    base_url="http://localhost:11434",
    temperature=0.8
)
manager.set_default("my_custom_llm")
```

## ðŸ“Š Comparaison des Fournisseurs

| Fournisseur | Avantages | InconvÃ©nients |
|------------|-----------|---------------|
| **Ollama** | Gratuit, local, privÃ© | NÃ©cessite GPU |
| **OpenAI** | Rapide, fiable | Payant, API externe |
| **HuggingFace** | Gratuit (limitÃ©), nombreux modÃ¨les | Rate limits |
| **Anthropic** | TrÃ¨s performant | Payant, API externe |

## âœ… Checklist

- [ ] Ollama configurÃ©
- [ ] OpenAI configurÃ© (optionnel)
- [ ] HuggingFace configurÃ© (optionnel)
- [ ] Anthropic configurÃ© (optionnel)
- [ ] Test avec diffÃ©rents LLM

---

**âœ… Support multi-LLM implÃ©mentÃ© !**

